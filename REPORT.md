# Is there a "sounds like AI" direction in the residual stream?

## Executive Summary
This research investigated whether the stylistic quality of being "AI-generated" is represented as a linear direction in the residual stream of Large Language Models (LLMs). Using the RAID dataset and Representation Engineering (RepE) techniques, we identified a "sounds like AI" direction in the middle layers of the Qwen2.5-1.5B model. We found that:
1. AI-generated text is highly linearly separable from human-written text in the residual stream, even at early layers.
2. Steering activations along this identified direction causally shifts the style of the model's output. Subtracting the AI direction from a prompt completion reduced its predicted "AI-ness" from 36% to 0.5%, while adding it increased it to 67%.
3. The identified direction captures stylistic markers such as objective tone, formal vocabulary, and specific structural transitions.

## Goal
The goal of this study was to test the **Linear Representation Hypothesis** for the abstract concept of "AI-like style." Understanding this representation is crucial for AI detection and for controlling model behavior to be more or less anthropomorphic.

## Data Construction

### Dataset Description
We used a sampled version of the **RAID** dataset (liamdugan/raid), consisting of:
- 100 Human-written scientific abstracts.
- 100 AI-generated scientific abstracts (generated by Llama-2-Chat).

### Data Quality
- The dataset was perfectly balanced (100 samples per class).
- Texts were truncated to 512 tokens for consistency.
- A potential confound was identified: AI-generated abstracts frequently started with "In this paper/abstract...", while human abstracts were more diverse.

## Experiment Description

### Methodology
We extracted residual stream activations (both last-token and mean-pooled) from all 29 layers of the **Qwen2.5-1.5B** model. We used the **Difference-in-Means** method to identify the "AI direction":
`V_ai = Mean(Activations_AI) - Mean(Activations_Human)`

### Implementation Details
- **Model**: Qwen2.5-1.5B (running in 16-bit precision).
- **Tooling**: `transformers`, `torch`, `scikit-learn`.
- **Steering**: A forward hook was used to add/subtract the AI direction at layer 14 during the generation process.

### Experimental Protocol
1. **Extraction**: Collect activations for all 200 samples.
2. **Analysis**: Train logistic regression probes for each layer to measure separability.
3. **Steering**: Generate text completions for human and AI prompts with steering coefficients of -5.0, 0, and +5.0.
4. **Evaluation**: Use the trained probe from step 2 to score the steered outputs.

## Raw Results

### Probe Accuracy
| Feature Type | Layer | Accuracy |
|--------------|-------|----------|
| Last Token   | 1     | 1.00     |
| Mean Pooled  | 14    | 1.00     |

*Note: The perfect accuracy at early layers is likely due to the "In this paper" prefix artifact.*

### Steering Evaluation (Layer 14)
| Prompt Start | Coefficient | AI Probability (Probe) |
|--------------|-------------|-------------------------|
| "The recent advancements..." | -5.0 (Subtract AI) | 0.0051 |
| "The recent advancements..." | 0.0 (Neutral) | 0.3622 |
| "The recent advancements..." | 5.0 (Add AI) | 0.6713 |

## Result Analysis

### Key Findings
1. **Causal Steering**: Manipulating the residual stream along the AI direction significantly changes the stylistic output. Subtracting the direction lead to more personal language ("we have now collected", "impossible to understand"), while adding it lead to more corporate/technical language ("integration of machine learning", "making it easier than ever").
2. **Early Detection**: The model's internal representations distinguish between its own "style" and human style almost immediately (Layer 0/1). This suggests that "AI-ness" is deeply encoded in the distribution of initial tokens/embeddings for this dataset.

### Visualizations
Plots of probe accuracy by layer and cosine similarity between layers were generated in the `figures/` directory.

## Conclusions
Our results support the hypothesis that "sounding like an AI" is a linear feature in the residual stream. While the specific direction found is tied to the prompt style of the RAID dataset, the causal success of steering indicates that LLMs possess a "stylistic axis" that can be manipulated to control the perceived origin of the text.

## Next Steps
1. **Cross-Model Validation**: Test if the AI direction found in Qwen can detect text from GPT-4 or Claude.
2. **De-biasing**: Use this direction to remove "AI-isms" from model responses to make them more natural.
3. **Robustness**: Re-run experiments with the "In this paper" prefix removed to find a more semantic AI direction.
