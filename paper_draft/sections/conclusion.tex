\section{Conclusion}
\label{sec:conclusion}

In this study, we investigated the internal representation of ``AI-style'' in the residual stream of the \qwen model. By applying Representation Engineering techniques to the \raid dataset, we identified a linear direction that captures the stylistic quality of being AI-generated. Our results demonstrate that this quality is highly linearly separable, achieving 100\% probe accuracy at early layers. More importantly, we showed that this direction is causally relevant: steering model activations along this axis allows for the precise manipulation of the model's stylistic output, shifting it from a personal, human-like tone to a formal, technical tone.

Our findings contribute to the growing body of evidence for the Linear Representation Hypothesis and suggest that LLMs possess internal stylistic axes that can be precisely controlled. This work opens new avenues for mechanistic AI detection and for the fine-grained control of model personas. Future research will focus on the universality of these directions across different model architectures and diverse writing domains.