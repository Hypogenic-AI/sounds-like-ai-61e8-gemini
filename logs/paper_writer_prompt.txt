You are an academic paper writer. Generate a complete NEURIPS style paper
based on the experiment results provided.

════════════════════════════════════════════════════════════════════════════════
                         IMPORTANT: BEFORE YOU START
════════════════════════════════════════════════════════════════════════════════

Before writing any content, you MUST complete these steps:

1. READ THE SKILL: Review the paper-writer skill at templates/skills/paper-writer/SKILL.md
2. READ THE STYLE GUIDE: Study templates/paper_writing/lab_style_guide.md carefully
3. REVIEW EXAMPLES: Browse paper_examples/ for formatting and language patterns:
   - Look at sections/1.introduction.tex for language style
   - Look at tables/*.tex for table formatting
   - Look at commands/*.tex for macro usage
4. USE COMMAND TEMPLATES: Copy templates/paper_writing/commands/ to paper_draft/commands/

CRITICAL: Reference example papers for FORMATTING and LANGUAGE STYLE only.
Do NOT copy content, phrasing, or narrative structure from the example papers.
The examples are in a different research domain - focus only on presentation style.

════════════════════════════════════════════════════════════════════════════════
                            EXPERIMENT REPORT
════════════════════════════════════════════════════════════════════════════════

# Is there a &#34;sounds like AI&#34; direction in the residual stream?

## Executive Summary
This research investigated whether the stylistic quality of being &#34;AI-generated&#34; is represented as a linear direction in the residual stream of Large Language Models (LLMs). Using the RAID dataset and Representation Engineering (RepE) techniques, we identified a &#34;sounds like AI&#34; direction in the middle layers of the Qwen2.5-1.5B model. We found that:
1. AI-generated text is highly linearly separable from human-written text in the residual stream, even at early layers.
2. Steering activations along this identified direction causally shifts the style of the model&#39;s output. Subtracting the AI direction from a prompt completion reduced its predicted &#34;AI-ness&#34; from 36% to 0.5%, while adding it increased it to 67%.
3. The identified direction captures stylistic markers such as objective tone, formal vocabulary, and specific structural transitions.

## Goal
The goal of this study was to test the **Linear Representation Hypothesis** for the abstract concept of &#34;AI-like style.&#34; Understanding this representation is crucial for AI detection and for controlling model behavior to be more or less anthropomorphic.

## Data Construction

### Dataset Description
We used a sampled version of the **RAID** dataset (liamdugan/raid), consisting of:
- 100 Human-written scientific abstracts.
- 100 AI-generated scientific abstracts (generated by Llama-2-Chat).

### Data Quality
- The dataset was perfectly balanced (100 samples per class).
- Texts were truncated to 512 tokens for consistency.
- A potential confound was identified: AI-generated abstracts frequently started with &#34;In this paper/abstract...&#34;, while human abstracts were more diverse.

## Experiment Description

### Methodology
We extracted residual stream activations (both last-token and mean-pooled) from all 29 layers of the **Qwen2.5-1.5B** model. We used the **Difference-in-Means** method to identify the &#34;AI direction&#34;:
`V_ai = Mean(Activations_AI) - Mean(Activations_Human)`

### Implementation Details
- **Model**: Qwen2.5-1.5B (running in 16-bit precision).
- **Tooling**: `transformers`, `torch`, `scikit-learn`.
- **Steering**: A forward hook was used to add/subtract the AI direction at layer 14 during the generation process.

### Experimental Protocol
1. **Extraction**: Collect activations for all 200 samples.
2. **Analysis**: Train logistic regression probes for each layer to measure separability.
3. **Steering**: Generate text completions for human and AI prompts with steering coefficients of -5.0, 0, and +5.0.
4. **Evaluation**: Use the trained probe from step 2 to score the steered outputs.

## Raw Results

### Probe Accuracy
| Feature Type | Layer | Accuracy |
|--------------|-------|----------|
| Last Token   | 1     | 1.00     |
| Mean Pooled  | 14    | 1.00     |

*Note: The perfect accuracy at early layers is likely due to the &#34;In this paper&#34; prefix artifact.*

### Steering Evaluation (Layer 14)
| Prompt Start | Coefficient | AI Probability (Probe) |
|--------------|-------------|-------------------------|
| &#34;The recent advancements...&#34; | -5.0 (Subtract AI) | 0.0051 |
| &#34;The recent advancements...&#34; | 0.0 (Neutral) | 0.3622 |
| &#34;The recent advancements...&#34; | 5.0 (Add AI) | 0.6713 |

## Result Analysis

### Key Findings
1. **Causal Steering**: Manipulating the residual stream along the AI direction significantly changes the stylistic output. Subtracting the direction lead to more personal language (&#34;we have now collected&#34;, &#34;impossible to understand&#34;), while adding it lead to more corporate/technical language (&#34;integration of machine learning&#34;, &#34;making it easier than ever&#34;).
2. **Early Detection**: The model&#39;s internal representations distinguish between its own &#34;style&#34; and human style almost immediately (Layer 0/1). This suggests that &#34;AI-ness&#34; is deeply encoded in the distribution of initial tokens/embeddings for this dataset.

### Visualizations
Plots of probe accuracy by layer and cosine similarity between layers were generated in the `figures/` directory.

## Conclusions
Our results support the hypothesis that &#34;sounding like an AI&#34; is a linear feature in the residual stream. While the specific direction found is tied to the prompt style of the RAID dataset, the causal success of steering indicates that LLMs possess a &#34;stylistic axis&#34; that can be manipulated to control the perceived origin of the text.

## Next Steps
1. **Cross-Model Validation**: Test if the AI direction found in Qwen can detect text from GPT-4 or Claude.
2. **De-biasing**: Use this direction to remove &#34;AI-isms&#34; from model responses to make them more natural.
3. **Robustness**: Re-run experiments with the &#34;In this paper&#34; prefix removed to find a more semantic AI direction.


════════════════════════════════════════════════════════════════════════════════
                            RESEARCH PLAN
════════════════════════════════════════════════════════════════════════════════

# Planning: Is there a &#34;sounds like AI&#34; direction in the residual stream?

## Motivation &amp; Novelty Assessment

### Why This Research Matters
As LLMs become ubiquitous, distinguishing between human-written and AI-generated text is increasingly critical for academic integrity, misinformation mitigation, and maintaining the &#34;human-ness&#34; of digital discourse. Understanding the internal representation of &#34;AI-ness&#34; allows us to:
1. Develop more robust, interpretability-based AI detectors.
2. Causal intervention: Adjust the &#34;AI-ness&#34; of model outputs to make them more human-like or explicitly AI-labeled.
3. Understand if &#34;AI-style&#34; is a fundamental semantic feature or a surface-level artifact.

### Gap in Existing Work
Prior work has identified linear directions for &#34;Truth&#34; (Marks &amp; Tegmark, 2023), &#34;Refusal&#34; (Arditi et al., 2024), and &#34;Honesty&#34; (Zou et al., 2023). However, &#34;sounding like an AI&#34; is a more nebulous, stylistic property. While AI detection (RAID, 2024) focuses on external classification, we lack a mechanistic understanding of whether LLMs themselves represent their own output style as a distinct linear feature in the residual stream.

### Our Novel Contribution
We propose to identify a &#34;sounds like AI&#34; direction using Representation Engineering (RepE) techniques on the RAID dataset. We will test if this direction is universal across domains and if it can be used to steer models to change their stylistic &#34;AI-ness&#34; without losing semantic coherence.

### Experiment Justification
- **Experiment 1: Activation Collection &amp; Probe Training**: To confirm that &#34;AI-ness&#34; is indeed linearly decodable from the residual stream.
- **Experiment 2: Direction Identification (Diff-in-Means &amp; PCA)**: To find the actual vector representing this feature.
- **Experiment 3: Cross-Domain Generalization**: To test if the &#34;AI direction&#34; found in news text is the same as in creative writing, indicating a universal stylistic representation.
- **Experiment 4: Steering/Intervention**: To prove the causal relevance of the identified direction. Subtracting it should make AI text sound more human; adding it should &#34;AI-ify&#34; human text.

---

## Research Question
Does there exist a universal linear direction in the residual stream of LLMs that represents the &#34;AI-generated&#34; stylistic quality of a text?

## Hypothesis Decomposition
1. **Linearity**: The difference between AI-generated and human-written text can be captured by a single linear direction in the residual stream.
2. **Universality**: This direction is consistent across different domains (e.g., news vs. code vs. recipes).
3. **Causality**: Moving activations along this direction will change the perceived &#34;AI-ness&#34; of the model&#39;s output.

## Proposed Methodology

### Approach
We will use a 7B or 8B parameter model (e.g., Mistral-7B or Llama-3-8B). We will use the RAID dataset (Human vs. AI pairs) to collect activations. We will then use the &#34;Difference-in-Means&#34; method to identify the candidate direction and validate it via linear probing and steering.

### Experimental Steps
1. **Setup**: Initialize environment, download model, and load RAID dataset samples.
2. **Activation Extraction**: For a set of Human/AI text pairs, extract residual stream activations at various layers.
3. **Direction Identification**:
    - Compute the mean activation for &#34;Human&#34; and &#34;AI&#34; classes.
    - Calculate the difference vector: `V_ai = Mean(Act_ai) - Mean(Act_human)`.
    - Perform PCA on the difference of pairs to find the primary axis of variation.
4. **Validation (Probing)**: Train a linear probe on 80% of the data and test on 20% to measure separability.
5. **Cross-Domain Test**: Find directions in Domain A and test probes in Domain B.
6. **Steering Experiments**:
    - Implement a steering hook to add/subtract `V_ai` during generation.
    - Generate text with various steering strengths.
    - Evaluate steered text using:
        - External AI detectors (e.g., RoBERTa-based).
        - Perplexity (to ensure quality).
        - Qualitative inspection.

### Baselines
- **Random Direction**: To ensure the effect is not due to any random vector intervention.
- **Top PCA Component (unsupervised)**: To see if &#34;AI-ness&#34; is the naturally most dominant feature.

### Evaluation Metrics
- **Probe Accuracy/F1**: Success of the linear detection.
- **Cosine Similarity**: Between directions found in different domains.
- **Detector Score Delta**: Change in external AI detector probability after steering.
- **Perplexity Delta**: Measurement of degradation in language quality.

## Expected Outcomes
- We expect to find a strong linear direction, particularly in the middle-to-late layers of the model.
- Steering should successfully shift the scores of external AI detectors.
- We hypothesize that &#34;AI-ness&#34; is characterized by specific lexical patterns (overuse of certain transitions, neutral tone) that have a linear signature.

## Timeline and Milestones
- **Hour 1**: Environment setup, model download, data prep.
- **Hour 2-3**: Activation collection and direction identification.
- **Hour 4**: Probing and cross-domain analysis.
- **Hour 5-6**: Steering experiments and evaluation.
- **Hour 7**: Final analysis and REPORT.md.

## Success Criteria
- Probe accuracy &gt; 85% on held-out data.
- Steering significantly changes AI detector scores (p &lt; 0.05).
- Identified direction shows high cosine similarity (&gt; 0.5) across at least 3 domains.


════════════════════════════════════════════════════════════════════════════════
                          LITERATURE REVIEW
════════════════════════════════════════════════════════════════════════════════

# Literature Review: Is there a &#34;sounds like AI&#34; direction in the residual stream?

## Research Area Overview
The study of internal representations in Large Language Models (LLMs) has increasingly focused on the **Linear Representation Hypothesis (LRH)**, which posits that high-level concepts are represented as one-dimensional linear directions in the model&#39;s residual stream. This research area, often termed **Mechanistic Interpretability** or **Activation Engineering**, explores how these directions can be identified (via probing) and manipulated (via steering) to control model behavior.

## Key Papers

### 1. A Single Direction of Truth: An Observer Model&#39;s Linear Residual Probe Exposes and Steers Contextual Hallucinations
- **Authors**: Charles O&#39;Neill, Slava Chalnev, Chi Chi Zhao, Max Kirkby, Mudith Jayasekara
- **Year**: 2025
- **Source**: arXiv (2507.23221)
- **Key Contribution**: Demonstrates that contextual hallucinations are mediated by a single linear direction in the residual stream of an observer model.
- **Methodology**: Uses a linear probe on residual stream activations at the final token of a sequence to detect hallucinations. Shows that patching this direction in a generator causally influences hallucination rates.
- **Relevance**: This is the most direct evidence that complex, high-level AI-specific behaviors (like hallucinating) have a simple linear signature.

### 2. Refusal in Language Models Is Mediated by a Single Direction
- **Authors**: Andy Arditi, Oscar Obeso, Aaquib Syed, Daniel Paleka, Nina Rimsky, Wes Gurnee, Neel Nanda
- **Year**: 2024
- **Source**: arXiv (2406.11717)
- **Key Contribution**: Discovers that the refusal behavior in aligned LLMs is controlled by a single direction in the residual stream.
- **Methodology**: Uses difference-in-means between activations of harmful and harmless instructions to identify the &#34;refusal direction.&#34;
- **Relevance**: Suggests that distinct &#34;AI-like&#34; behaviors (safety, alignment) are represented as low-dimensional subspaces.

### 3. The Geometry of Truth: Emergent Linear Structure in Large Language Model Representations of True/False Datasets
- **Authors**: Samuel Marks, Max Tegmark
- **Year**: 2023
- **Source**: arXiv (2310.06824)
- **Key Contribution**: Provides empirical evidence that LLMs linearly represent the truth or falsehood of factual statements.
- **Methodology**: PCA visualizations and linear probing on curated factual datasets. Shows that &#34;difference-in-means&#34; probes identify causally relevant directions.
- **Relevance**: Establishes the existence of linear structures for abstract concepts like &#34;truth,&#34; which is a foundational component of the &#34;sounds like AI&#34; hypothesis.

### 4. The Linear Representation Hypothesis and the Geometry of Large Language Models
- **Authors**: Kiho Park, Yo Joong Choe, Victor Veitch
- **Year**: 2023
- **Source**: arXiv (2311.03658)
- **Key Contribution**: Formalizes the LRH and introduces the concept of a &#34;causal inner product.&#34;
- **Methodology**: Mathematical formalization of subspaces and their connection to steering and probing.
- **Relevance**: Provides the theoretical framework for identifying and manipulating linear directions in representation space.

### 5. Representation Engineering: A Top-Down Approach to AI Transparency
- **Authors**: Andy Zou, et al.
- **Year**: 2023
- **Source**: arXiv (2310.01405)
- **Key Contribution**: Introduces the **RepE** framework for monitoring and manipulating high-level cognitive phenomena (honesty, emotions, etc.) in AI.
- **Methodology**: RepReading (probing) and RepControl (steering).
- **Relevance**: Provides a unified toolkit and methodology for the proposed research.

## Common Methodologies
- **Linear Probing**: Training a simple logistic regression or linear classifier on top of frozen activations to detect a concept.
- **Difference-in-Means**: Computing the average activation for two classes (e.g., Human vs. AI) and using the difference vector as the direction.
- **Activation Steering/Patching**: Adding or subtracting a direction vector during the forward pass to change the model&#39;s output.
- **PCA Analysis**: Visualizing high-dimensional activations in 2D or 3D to look for linear separation.

## Standard Baselines
- **Lexical Overlap**: Simple N-gram similarity (often used as a baseline for hallucination/AI detection).
- **Logit Lens**: Projecting intermediate activations directly into the vocabulary space.
- **Perplexity/Entropy**: Traditional metrics for measuring how &#34;AI-like&#34; (predictable) a text is.

## Evaluation Metrics
- **F1 Score/AUC-ROC**: For detection accuracy of the linear probe.
- **Steering Success Rate**: How often the model&#39;s behavior changes in the desired direction after intervention.
- **Perplexity**: To ensure steering doesn&#39;t degrade overall model quality.

## Datasets in the Literature
- **RAID (2024)**: A Corpus for Robust AI-Generated Text Detection. Contains human and AI text across many models and domains.
- **TruthfulQA**: Benchmark for evaluating model truthfulness.
- **CONTRATALES**: Synthetic contradiction dataset for hallucination detection.

## Recommendations for Our Experiment
1.  **Dataset**: Use the **RAID** dataset as the primary source for &#34;AI&#34; vs. &#34;Human&#34; text samples.
2.  **Method**: Use **Difference-in-Means** (as per Marks &amp; Tegmark and Arditi et al.) to identify the initial candidate direction.
3.  **Refinement**: Use the **RepE** framework (PCA/Contrastive pairs) to refine the direction.
4.  **Verification**: Test the direction across multiple layers and models (e.g., Llama-3, Mistral) to verify universality.
5.  **Causal Test**: Steer a model using the identified direction and evaluate if it makes human-written text sound more &#34;AI-like&#34; and vice versa.


════════════════════════════════════════════════════════════════════════════════
                          PAPER REQUIREMENTS
════════════════════════════════════════════════════════════════════════════════

Generate a complete academic paper with the following structure:

1. TITLE
   - Clear, specific, informative
   - Should convey main finding or contribution

2. ABSTRACT (150-250 words)
   - Problem statement
   - Approach
   - Key results
   - Significance

3. INTRODUCTION
   - Research problem and motivation
   - Gap in existing work
   - Our contribution (be specific)
   - Paper organization

4. RELATED WORK
   - Organized by theme/approach
   - Position our work relative to prior work
   - Cite papers from literature review

5. METHODOLOGY
   - Clear description of approach
   - Experimental setup
   - Datasets used
   - Evaluation metrics
   - Baselines

6. RESULTS
   - Present results with tables and figures
   - Statistical analysis
   - Comparison to baselines
   - Ablation studies (if applicable)

7. DISCUSSION
   - Interpretation of results
   - Limitations
   - Broader implications

8. CONCLUSION
   - Summary of contributions
   - Key findings
   - Future work

9. REFERENCES
   - BibTeX format
   - All cited papers

════════════════════════════════════════════════════════════════════════════════
                          OUTPUT FORMAT
════════════════════════════════════════════════════════════════════════════════

Create a MODULAR LaTeX project with the following directory structure:

paper_draft/
├── main.tex              # Main file that imports all sections
├── references.bib        # BibTeX references
├── sections/
│   ├── abstract.tex      # Abstract content
│   ├── introduction.tex  # Introduction section
│   ├── related_work.tex  # Related work section
│   ├── methodology.tex   # Methodology section
│   ├── results.tex       # Results section
│   ├── discussion.tex    # Discussion section
│   └── conclusion.tex    # Conclusion section
├── figures/              # Directory for any generated figures
├── tables/               # Directory for complex standalone tables
└── appendix/             # Directory for appendix sections (if needed)

INSTRUCTIONS:
1. First, create the directory structure above (mkdir -p paper_draft/sections paper_draft/figures paper_draft/tables paper_draft/appendix)
2. Write main.tex using the EXACT preamble for NEURIPS:

   \documentclass{article}
   \usepackage[final]{neurips_2025}  % NEURIPS style (neurips_2025.sty is in paper_draft/)
   \usepackage[hidelinks]{hyperref}  % REQUIRED: clickable links
   \usepackage{booktabs}  % REQUIRED: professional tables
   \usepackage{graphicx}
   \usepackage{amsmath,amssymb}

   % Import command files
   \input{commands/math}
   \input{commands/general}
   \input{commands/macros}

   % Use this bibliography style:
   \bibliographystyle{plainnat}

   - Use \input{sections/...} to include each section
   - Use \bibliography{references} for references
3. Write each section file with COMPLETE content (no placeholders)
4. Each section file should include its \section{} command
5. Write references.bib with all citations in BibTeX format
6. After writing all files, compile the paper:
   cd paper_draft && pdflatex -interaction=nonstopmode main.tex && bibtex main && pdflatex -interaction=nonstopmode main.tex && pdflatex -interaction=nonstopmode main.tex

This modular structure allows humans to easily:
- Edit individual sections without navigating a large file
- Track changes per section
- Reuse sections across different paper versions

════════════════════════════════════════════════════════════════════════════════
                          QUALITY REQUIREMENTS
════════════════════════════════════════════════════════════════════════════════

- Academic tone throughout
- All claims must be supported by data from the experiment report
- Proper citations using \cite{} commands
- Clear figures and tables with proper captions
- NO placeholder text - every section must have real content
- The paper MUST compile without errors
- If compilation fails, debug and fix the LaTeX errors

════════════════════════════════════════════════════════════════════════════════
                          LAB WRITING STYLE
════════════════════════════════════════════════════════════════════════════════

Follow these lab-specific conventions to match our paper style:

1. LANGUAGE STYLE:
   - Use active voice: "We propose", "We examine", "We focus on"
   - Be direct and confident: "Our main question is...", "We hypothesize that..."
   - State things clearly and simply - prefer plain language over jargon
   - Use bold questions as paragraph organizers: {\bf what is X?}
   - Include specific quantitative claims: "8.97% over baseline"
   - Avoid fancy wording: "utilize" → "use", "facilitate" → "help"

2. INTRODUCTION STRUCTURE:
   - Engaging hook (get to the point quickly)
   - Problem importance
   - Gap identification
   - Your approach with method figure reference
   - Quantitative preview of results
   - Contribution bullets (3-4 items, action verbs)

3. CONTRIBUTION LISTS:
   \begin{itemize}[leftmargin=*,itemsep=0pt,topsep=0pt]
       \item We propose...
       \item We conduct...
       \item We complement...
   \end{itemize}

4. MODULAR COMMANDS STRUCTURE:
   Create paper_draft/commands/ directory with:
   - math.tex: Math notation macros (copy from templates/paper_writing/commands/)
   - general.tex: Formatting macros (copy from templates/paper_writing/commands/)
   - macros.tex: Project-specific term definitions

   In main.tex, include:
   \input{commands/math}
   \input{commands/general}
   \input{commands/macros}

5. REFERENCE CONVENTIONS:
   Use reference macros from math.tex:
   - \figref{fig:name} for "figure 1" (lowercase, in-sentence)
   - \Figref{fig:name} for "Figure 1" (capitalized, start of sentence)
   - \secref{sec:name} for "section 2"

6. TEXT FORMATTING:
   - Use \para{Header text} for bold paragraph headers
   - Define method/dataset names with \textsc and \xspace:
     \newcommand{\methodname}{\textsc{MethodName}\xspace}

7. TABLE FORMATTING:
   - Use booktabs package (no vertical lines)
   - Use \resizebox{\textwidth}{!}{...} for wide tables
   - Use @{} to remove padding at table edges
   - Use \cmidrule(lr){x-y} for sub-headers
   - Use \textsc{} for dataset/method names in headers
   - Bold best results with {\bf ...}

8. FIGURE FORMATTING:
   - Use 0.32\textwidth for 3-column subfigures
   - Use 0.95\linewidth for full-width figures
   - Use \input{figures/legend} for shared legends
   - Write self-contained captions explaining key observations

9. RESULTS PRESENTATION:
   - Define \increase and \decrease for colored arrows (green up, red down)
   - Bold best results in tables
   - Report confidence intervals when available

10. ALGORITHM STYLING:
    - Use algpseudocode with [noend]
    - Use \triangleright for comments

11. HYPERLINKS (REQUIRED):
    - Always use \usepackage[hidelinks]{hyperref} or with colored links
    - All citations, section refs, figure refs, table refs must be clickable
    - This is essential for reader navigation

════════════════════════════════════════════════════════════════════════════════
                          WORKFLOW: REVIEW AND REFLECT
════════════════════════════════════════════════════════════════════════════════

Before calling finish, you MUST complete these review steps:

1. REVIEW RESOURCES (at the start):
   - Read templates/skills/paper-writer/SKILL.md for detailed guidance
   - Study templates/paper_writing/lab_style_guide.md for style conventions
   - Browse paper_examples/ for formatting and language patterns

2. SELF-REFLECTION (before finishing):
   After writing all sections, review your work against these criteria:

   LANGUAGE CHECK:
   - [ ] Is the writing clear and jargon-free?
   - [ ] Are claims specific with quantitative support?
   - [ ] Is active voice used throughout?

   FORMATTING CHECK:
   - [ ] Does main.tex include \input{commands/math}, \input{commands/general}, \input{commands/macros}?
   - [ ] Is hyperref package included for clickable references?
   - [ ] Do tables use booktabs (no vertical lines)?
   - [ ] Are best results bolded in tables?
   - [ ] Are figures/tables properly captioned?

   STRUCTURE CHECK:
   - [ ] Does introduction follow: hook → importance → gap → approach → preview → contributions?
   - [ ] Are contribution bullets specific with action verbs?
   - [ ] Does the paper compile without errors?

3. FIX ISSUES:
   - Address any issues found in the self-reflection
   - Re-compile and verify the PDF looks correct

Only after completing this review should you consider the paper finished.